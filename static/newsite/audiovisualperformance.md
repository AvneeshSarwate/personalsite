<b>Audiovisual Performance</b>
===============
<div>[Back to main page](http://www.avneeshsarwate.com#)</div>

Inspired by the likes of Oskar Fischinger and Ryoji Ikeda, I have been exploring audiovisual composition and improvisation. My goal was to create systems that would allow for realtime performance of music and graphics where, even if the music were improvised, the graphics would remain tightly synced to the music. In each piece, the graphical system is a program that listens to realtime MIDI input from the performance to modify the visuals in response to the music. The following pieces are the result of various strategies towards this aesthetic goal.

### <b>Piece 1</b>
For this piece, I used my custom MIDI live-looping system to perform the piece. When melodies matching certain abstract melodic templates (defined via regular expressions) are played, the system triggers gestures in the flock of moving circles.

<figure>
<iframe style="position: absolute; width: 100%; height: 100%;" src="https://www.youtube.com/embed/xOYPkdNwmNE" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>

### <b>Piece 2</b>
In this piece, the notes played launch particles into a simple physics environment with invisible gravity wells. 

### <b>Piece 3</b>
The sound in this piece is generated from a polyphonic-glissando synthesizer. The green sliders adjust the pitch of each individual voice. The blue sliders control the parameters of a tape-feedback simulation device. The motion of the red circles mirrors the interpolation of the microtonal chords, and the warping of the texture is reflective of the tape feedback, and controleld by the same parameters. 


<footer>*This site was built using  [jQuery](http://jquery.com/), [Marked](https://github.com/chjj/marked), and [Tufte CSS](https://github.com/edwardtufte/tufte-css)*</footer>